{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5873aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f43a50",
   "metadata": {},
   "source": [
    "## KNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d231c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanKNearestNeighbors:\n",
    "    \n",
    "    # Construtor\n",
    "    def __init__(self, x, y, k):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "    \n",
    "    # Getters\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "        \n",
    "    def getY(self):\n",
    "        return self.y\n",
    "    \n",
    "    def getK(self):\n",
    "        return self.k\n",
    "    \n",
    "    # Setters\n",
    "    def setX(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def setY(self, y):\n",
    "        self.y = y\n",
    "    \n",
    "    def setK(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    # Métodos\n",
    "    def distance(self, x1, x2):\n",
    "        return np.sqrt(((x1 - x2)**2).sum())\n",
    "    \n",
    "    def nearest(self, distances):\n",
    "        near = distances[0]\n",
    "        near_idx = 0\n",
    "        for i, d in enumerate(distances):\n",
    "            if d[0] < near[0]:\n",
    "                near = d\n",
    "                near_idx = i\n",
    "        return near, near_idx\n",
    "            \n",
    "    def k_nearest(self, distances):\n",
    "        k_near = np.zeros((self.k, self.x.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            k_near[i], near_idx = self.nearest(distances)\n",
    "            distances = np.delete(distances, near_idx, axis=0)\n",
    "        return k_near\n",
    "    \n",
    "    def classify(self, new_x, append = False):\n",
    "        \n",
    "        distances = np.zeros(self.x.shape)\n",
    "        \n",
    "        for i, x in enumerate(self.x):\n",
    "            distances[i, 0] = self.distance(x, new_x)\n",
    "            distances[i, 1] = self.y[i]\n",
    "            \n",
    "        k_near = self.k_nearest(distances)\n",
    "        clss = round(k_near[:, 1].mean())\n",
    "        \n",
    "        if append:\n",
    "            self.x = np.vstack((self.x, new_x))\n",
    "            self.y = np.vstack((self.y, clss))\n",
    "        \n",
    "        return clss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd5e6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MahalanobisKNearestNeighbors:\n",
    "    \n",
    "    # Construtor\n",
    "    def __init__(self, x, y, k):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.classes = int(np.amax(y) + 1) # Assume que a primeira classe é 0, a segunda é 1... etc\n",
    "        self.n_per_class = np.zeros((self.classes, 1))\n",
    "        self.cov = np.zeros((self.classes, x.shape[1], x.shape[1]))\n",
    "        self.inv_cov\n",
    "        \n",
    "        # Calcula n_per_class\n",
    "        for clss in range(self.classes):\n",
    "            self.n_per_class[clss] = len(y[y==clss])\n",
    "        \n",
    "        # Calcula a variância de cada feature para cada classe\n",
    "        for clss in range(self.classes):\n",
    "            self.cov[clss] = np.cov(x[(y == clss)[:, 0], :], rowvar=False)/self.n_per_class[clss]\n",
    "            self.cov[clss] += np.identity(self.cov.shape[1]) * 1e-10\n",
    "        \n",
    "        self.inv_cov = np.linalg.inv(self.cov)\n",
    "    \n",
    "    # Getters\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "        \n",
    "    def getY(self):\n",
    "        return self.y\n",
    "    \n",
    "    def getK(self):\n",
    "        return self.k\n",
    "    \n",
    "    def getCov(self):\n",
    "        return self.cov\n",
    "    \n",
    "    # Setters\n",
    "    def setXY(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.classes = np.amax(y) + 1 # Assume que a primeira classe é 0, a segunda é 1... etc\n",
    "        self.n_per_class = np.zeros((self.classes, 1))\n",
    "        self.cov = np.zeros((self.classes, x.shape[1], x.shape[1]))\n",
    "        \n",
    "        # Calcula n_per_class\n",
    "        for clss in range(self.classes):\n",
    "            self.n_per_class[clss] = len(y[y==clss])\n",
    "        \n",
    "        # Calcula a variância de cada feature para cada classe\n",
    "        for clss in range(self.classes):\n",
    "            self.cov[clss] = np.cov(x[y[:] == clss, :], rowvar=False)/self.n_per_class[clss]\n",
    "            self.cov[clss] += np.identity(self.cov.shape[1]) * 1e-10\n",
    "        \n",
    "        self.inv_cov = np.linalg.inv(self.cov)\n",
    "    \n",
    "    def setK(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    # Métodos\n",
    "    def distance(self, x1, x2):\n",
    "        diff = x1 - x2\n",
    "        print(diff.T.shape)\n",
    "        print(self.inv_cov.shape)\n",
    "        print(diff.shape)\n",
    "        return np.sqrt((diff.T @ self.inv_cov @ diff).sum())\n",
    "    \n",
    "    def nearest(self, distances):\n",
    "        near = distances[0]\n",
    "        near_idx = 0\n",
    "        for i, d in enumerate(distances):\n",
    "            if d[0] < near[0]:\n",
    "                near = d\n",
    "                near_idx = i\n",
    "        return near, near_idx\n",
    "            \n",
    "    def k_nearest(self, distances):\n",
    "        k_near = np.zeros((self.k, self.x.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            k_near[i], near_idx = self.nearest(distances)\n",
    "            distances = np.delete(distances, near_idx, axis=0)\n",
    "        return k_near\n",
    "    \n",
    "    def classify(self, new_x, append = False):\n",
    "        \n",
    "        distances = np.zeros(self.x.shape)\n",
    "        \n",
    "        for i, x in enumerate(self.x):\n",
    "            distances[i, 0] = self.distance(x, new_x)\n",
    "            distances[i, 1] = self.y[i]\n",
    "            \n",
    "        k_near = self.k_nearest(distances)\n",
    "        clss = round(k_near[:, 1].mean())\n",
    "        \n",
    "        if append:\n",
    "            self.x = np.vstack((self.x, new_x))\n",
    "            self.y = np.vstack((self.y, clss))\n",
    "        \n",
    "        return clss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42ba89",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8647394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(data):\n",
    "    np.random.seed(1200)\n",
    "    folds = []\n",
    "    splits = 10\n",
    "    indices = np.random.permutation(data.shape[0])\n",
    "    folds_idx = np.array_split(indices, splits)\n",
    "        \n",
    "    for i in range(0, splits):\n",
    "        train_idx = np.concatenate(folds_idx[:i] + folds_idx[i+1:])\n",
    "        test_idx = folds_idx[i]\n",
    "        folds.append((train_idx, test_idx))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942e4d1",
   "metadata": {},
   "source": [
    "## Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b56da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 22)\n",
      "(2, 21, 21)\n",
      "(22, 21)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 21 is different from 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4896/2310732101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# 1-NN Mahalanobis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mM1NN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMahalanobisKNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0my_m1nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM1NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 5-NN Mahalanobis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4896/1950537884.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, new_x, append)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4896/1950537884.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_cov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_cov\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 21 is different from 22)"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"kc2.csv\", delimiter=',')\n",
    "\n",
    "x = data[:, :21]\n",
    "y = data[:, 21].reshape(-1, 1)\n",
    "\n",
    "folds = kfold(x)\n",
    "\n",
    "acuracia        = np.zeros((6, 10))\n",
    "revocacao       = np.zeros((6, 10))\n",
    "precisao        = np.zeros((6, 10))\n",
    "f1_score        = np.zeros((6, 10))\n",
    "true_positives  = np.zeros((6, 10))\n",
    "false_positives = np.zeros((6, 10))\n",
    "false_negatives = np.zeros((6, 10))\n",
    "\n",
    "for f, (train_idx, test_idx) in enumerate(folds):\n",
    "#(train_idx, test_idx) = folds[0]\n",
    "\n",
    "    x_train = x[train_idx, :]\n",
    "    y_train = y[train_idx].reshape(-1,1)\n",
    "\n",
    "    x_test = x[test_idx, :]\n",
    "    y_test = y[test_idx].reshape(-1,1)\n",
    "\n",
    "    # 1-NN Euclideano \n",
    "    E1NN = EuclideanKNearestNeighbors(x_train, y_train, 1)\n",
    "    y_e1nn = E1NN.classify(x_test)\n",
    "    \n",
    "    # 5-NN Euclideano\n",
    "    E5NN = EuclideanKNearestNeighbors(x_train, y_train, 5)\n",
    "    y_e5nn = E5NN.classify(x_test) \n",
    "    \n",
    "    # 1-NN Mahalanobis\n",
    "    M1NN = MahalanobisKNearestNeighbors(x_train, y_train, 1)\n",
    "    y_m1nn = M1NN.classify(x_test)\n",
    "    \n",
    "    # 5-NN Mahalanobis\n",
    "    M5NN = MahalanobisKNearestNeighbors(x_train, y_train, 5)\n",
    "    y_m5nn = M5NN.classify(x_test)\n",
    "    \n",
    "    # Árvore de decisão com índice de Gini\n",
    "    GDTC = DecisionTreeClassifier(criterion='gini')\n",
    "    GDTC.fit(x_train, y_train)\n",
    "    y_gdtc = GDTC.predict(x_test)\n",
    "    \n",
    "    # Árvore de decisão com índice de entropia\n",
    "    EDTC = DecisionTreeClassifier(criterion='entropy')\n",
    "    EDTC.fit(x_train, y_train)\n",
    "    y_edtc = EDTC.predict(x_test)\n",
    "    \n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test[i] == y_e1nn[i]:\n",
    "            acuracia[0, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[0, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[0, f] += 1\n",
    "            else:\n",
    "                false_positives[0, f] += 1\n",
    "            \n",
    "        if y_test[i] == y_e5nn[i]:\n",
    "            acuracia[1, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[1, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[1, f] += 1\n",
    "            else:\n",
    "                false_positives[1, f] += 1\n",
    "        \n",
    "        if y_test[i] == y_m1nn[i]:\n",
    "            acuracia[2, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[2, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[2, f] += 1\n",
    "            else:\n",
    "                false_positives[2, f] += 1\n",
    "        \n",
    "        if y_test[i] == y_m5nn[i]:\n",
    "            acuracia[3, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[3, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[3, f] += 1\n",
    "            else:\n",
    "                false_positives[3, f] += 1\n",
    "        \n",
    "        if y_test[i] == y_gdtc[i]:\n",
    "            acuracia[4, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[4, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[4, f] += 1\n",
    "            else:\n",
    "                false_positives[4, f] += 1\n",
    "        \n",
    "        if y_test[i] == y_edtc[i]:\n",
    "            acuracia[5, f] += 1\n",
    "            if y_test == 1:\n",
    "                true_positives[5, f] += 1\n",
    "        else:\n",
    "            if y_test == 1:\n",
    "                false_negatives[5, f] += 1\n",
    "            else:\n",
    "                false_positives[5, f] += 1\n",
    "    \n",
    "    acuracia[:, f] /= y_test.shape[0]\n",
    "    revocacao[:, f] = true_positives[:, f]/(true_positives[:, f] + false_negatives[:, f])\n",
    "    precisao[:, f] = true_positives[:, f]/(true_positives[:, f] + false_positives[:, f])\n",
    "    f1_score[:, f] = (2 * precisao[:, f] * revocacao[:, f])/(precisao[:, f] + revocacao[:, f])\n",
    "\n",
    "    \n",
    "names = [\"1-NN Euclideano\", \n",
    "         \"5-NN Euclideano\", \n",
    "         \"1-NN Mahalanobis\",\n",
    "         \"5-NN Mahalanobis\", \n",
    "         \"Decision tree Gini\", \n",
    "         \"Decision tree Entropia\"]\n",
    "    \n",
    "plt.title(\"Média da acurácia\")\n",
    "\n",
    "plt.bar(names, acuracia.mean(axis=1), yerr=np.std(acuracia, axis=1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebd79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
